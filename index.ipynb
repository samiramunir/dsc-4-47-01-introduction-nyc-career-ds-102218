{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This lesson summarizes the topics we'll be covering in section 47 and why they'll be important to you as a data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "* Understand and explain what is covered in this section\n",
    "* Understand and explain why the section will help you to become a data scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders\n",
    "\n",
    "In this section, we'll dig into another, more advanced supervised learning technique: autoencoders. Autoencoders are unsupervised neural networks that use machine learning to do data compression for us. The aim of an autoencoder is to learn a compressed, distributed representation for the given data.\n",
    "\n",
    "### Introduction to Autoencoders\n",
    "We kick of the section by explaining what autoencoders (AEs) are, and why they are useful when you want to compress data. We'll the idea of coders and decoders to reconstruct the input in the output. You'll learn what the use is of autoencoders beyond data compression as well, and get a better understanding of AE features such as the AE loss function and AE hyperparameters.\n",
    "\n",
    "### Building Simple and Deep Autoencoders\n",
    "Next, you'll learn the basics in Keras on how to build a simple autoencoder (with one encoder and one decoder layer), and afterwards a deeper (three encoder and three decoder layers) network.\n",
    "\n",
    "### Denoising Autoencoders\n",
    "After your first experiences with autoencoders in Keras, you will look at Denoising Autoencoders (DAEs). The denoising autoencoder is trained to use a hidden layer to reconstruct a particular \"noisy\" input and uses that to generate a \"denoised\" output.\n",
    "\n",
    "### Convolutional Autoencoders\n",
    "Next, you'll learn about convolutional autoencoders and how combining convolutional neural networks and autoencoders has great applications such as image reconstruction and image colorization.\n",
    "\n",
    "### Neural Language Translation with seq2seq Models\n",
    "In the very last codealong of this section, we'll build a model that uses seq2seq models that follows a encoder-decoder approach to translate short English sentenses in French!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, you'll dive deeper into NLP in combination with deep Recurrent Neural Networks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
